[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hello all who visit. This blog is intended to showcase my work as a graduate student involved in understanding the Hsp90 chaperone, it’s client-chaperone folding cycle, and client specificity. One of the main goals of my research is to selectively modulate Hsp90 chaperone function to selectively impace its downstream client targets by mutation or allosteric small molecule binders."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BCB 504 My Data Blog",
    "section": "",
    "text": "Practice with Spatial Data\n\n\nMalaria, Ocean Currents, Baseball…\n\n\n\n\nPortfolio\n\n\nDataViz\n\n\nSpatial\n\n\nGGPlot\n\n\nAssignment\n\n\n\n\nMaps and Spatial Fields are fun!\n\n\n\n\n\n\nApr 10, 2023\n\n\nBarrie Robison\n\n\n\n\n\n\n  \n\n\n\n\nBCB 520 - Midterm Portfolio Post\n\n\nGun violence in the US\n\n\n\n\nMidterm\n\n\nData\n\n\nExploration\n\n\nViolence\n\n\nGuns\n\n\n\n\nWhat trend, if any, in gun violence is there in the US?\n\n\n\n\n\n\nMar 21, 2023\n\n\nErick Rios\n\n\n\n\n\n\n  \n\n\n\n\nASSIGNMENT 5\n\n\nVisualizations for Tabular Data\n\n\n\n\nAssignment\n\n\nDataViz\n\n\nTables\n\n\nScatterplot\n\n\nBarplot\n\n\nPiechart\n\n\n\n\nShould I trade these draft picks for this bag of magic beans…?\n\n\n\n\n\n\nMar 6, 2023\n\n\nBarrie Robison\n\n\n\n\n\n\n  \n\n\n\n\nASSIGNMENT 4\n\n\nMarks and Channels\n\n\n\n\nAssignment\n\n\nDataViz\n\n\nKnowledge\n\n\n\n\nThis post contains knowledge and fuel units for your yeast\n\n\n\n\n\n\nFeb 14, 2023\n\n\nErick Rios\n\n\n\n\n\n\n  \n\n\n\n\nAssignments 2 and 3\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\nInsert witty description\n\n\n\n\n\n\nFeb 6, 2023\n\n\nErick Rios\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nFeb 3, 2023\n\n\nErick Rios\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Assignment 2 and 3/index.html",
    "href": "posts/Assignment 2 and 3/index.html",
    "title": "Assignments 2 and 3",
    "section": "",
    "text": "In the quest to ensure data reproducibility, my goals are to:\n\nCollect data of interest.\nImport my data of interest into Rstudio.\nDescribe the data.\nIf time permits, host the data on a repository; probably github.\n\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "posts/Assignment 2 and 3/index.html#how-many-if-any-proteins-had-a-significant-change-in-their-steady-state-levels-in-at-least-one-mutant-condition",
    "href": "posts/Assignment 2 and 3/index.html#how-many-if-any-proteins-had-a-significant-change-in-their-steady-state-levels-in-at-least-one-mutant-condition",
    "title": "Assignments 2 and 3",
    "section": "How many, if any, proteins had a significant change in their steady-state levels in at least one mutant condition?",
    "text": "How many, if any, proteins had a significant change in their steady-state levels in at least one mutant condition?\n\nGene <- unique(Proteomic.Data$Gene[abs(Proteomic.Data$logFC) >= 1.5 &\n                                     Proteomic.Data$P.Value <= 0.055])\n\n\n\nCode\nHits <- paste(length(Gene), \"out of\", length(unique(Proteomic.Data$Gene)), \"proteins were significantly affected in at least one mutant condition; Here we consider any protein whose steady state level changed by at least 1.5 (|Log2FC|)\" )\n\nknitr::kable(Hits)\n\n\n\n\n\n\n\n\nx\n\n\n\n\n350 out of 2482 proteins were significantly affected in at least one mutant condition; Here we consider any protein whose steady state level changed by at least 1.5 (|Log2FC|)\n\n\n\n\n\nConsidering we found these genes of interest using the attributes ‘logFC’ and ‘P.Value’; lets use these attributes to visualize our findings.\n\n\nCode\nx <- Proteomic.Data$logFC\ny <- -log10(Proteomic.Data$P.Value)\n\ngroup <- rep(1, nrow(Proteomic.Data))               # Create group variable\ngroup[abs(x) >= 1.5 & y >= -log10(0.055)] <- 2\ngroup[abs(x) >= 1.5 & y <= -log10(0.055)] <- 3\n\nplot(x, y, \n     col = group, \n     pch = 20,\n     ylim = c(0,25),\n     xlim = c(-6.5, 6.5),\n     xlab = expression(\"Log\"[2]*\"Fold Change\"),\n     ylab = expression(\"-Log\"[10]*\"(P.Value)\")\n)\nabline(v = c(1.5, -1.5), col = \"red\", lty = 2)\nabline(h = -log10(0.055), col = \"red\", lty = 2)\ntext(x = 1.45, y = 24, labels = \"Decreased steady state levels \\n p value < 0.055\",\n     pos = 4, offset = .5)\ntext(x = -1.45, y = 24, labels = \"Increased steady state levels \\n p value < 0.055\",\n     pos = 2, offset = .5)\ntext(x = -4, y = -log10(0.055), labels = \"p value > 0.055\", pos = 1, offset = .5)\ntext(x = 4, y = -log10(0.055), labels = \"p value > 0.055\", pos = 1, offset = .5)\n\n\n\n\n\nWith this ‘volcano’ plot we visualized what was done prior when we searched for any proteins that met our criteria for significance. Those that met our criteria were marked pink and those that did not meet our criteria were marked black or light green. To better visualize the ‘barriers’ for significance, red-dashed lines were added. Proteins with positive logFC values had decreased levels and those with negative logFC values had increased levels. Although not relevant for future analysis, we can spot proteins with large changes in steady state levels, but unfortunately did not meet our threshold for statistical significance (light green) and this is was due to too much variance between the 3 biological replicates in the measurement of that protein."
  },
  {
    "objectID": "posts/Assignment 5/index.html",
    "href": "posts/Assignment 5/index.html",
    "title": "ASSIGNMENT 5",
    "section": "",
    "text": "In this assignment, we are going to practice creating visualizations for tabular data. Unlike previous assignments, however, this time we will all be using the same data sets. I’m doing this because I want everyone to engage in the same logic process and have the same design objectives in mind."
  },
  {
    "objectID": "posts/Assignment 5/index.html#scenario",
    "href": "posts/Assignment 5/index.html#scenario",
    "title": "ASSIGNMENT 5",
    "section": "SCENARIO",
    "text": "SCENARIO\nImagine you are a high priced data science consultant. One of your good friends, Cassandra Canuck, is an Assistant General Manager for the Vancouver Canucks, a team in the National Hockey League with a long, long…. long history of futility.\nCassandra tells you her boss, General Manager Hans Doofenschmirtz, is considering trading this year’s first round draft pick for two second round picks and one third round pick from another team. For the purposes of this exercise, let’s set the 2023 NHL draft order using the Tankathon Simulator. The NHL uses a lottery system in which the teams lowest in the standings have the highest odds of getting the first overall pick. I’ll simulate the lottery now…\nHOLY CRAP! The Vancouver Canucks jump up 6 spots, and will pick FIRST overall. Here is a screenshot:\n\nOur official scenario is this:\nVancouver receives: The 7th pick in the second round (39th overall), the 10th pick in the second round (42nd overall), and the 10th pick in the third round (74th overall).\nDetroit receives: The 1st pick in the first round (1st overall).\nDoofenschmirtz reasons that more draft picks are better, and is inclined to make the trade. Cassandra isn’t so sure…\nShe asks you to create some data visualizations she can show to her boss that might help him make the best decision."
  },
  {
    "objectID": "posts/Assignment 5/index.html#directions",
    "href": "posts/Assignment 5/index.html#directions",
    "title": "ASSIGNMENT 5",
    "section": "DIRECTIONS",
    "text": "DIRECTIONS\nCreate a new post in your portfolio for this assignment. Call it something cool, like NHL draft analysis, or Hockey Analytics, or John Wick….\nCopy the data files from the repository, and maybe also the .qmd file.\nUse the .qmd file as the backbone of your assignment, changing the code and the markdown text as you go."
  },
  {
    "objectID": "posts/Assignment 5/index.html#the-data",
    "href": "posts/Assignment 5/index.html#the-data",
    "title": "ASSIGNMENT 5",
    "section": "THE DATA",
    "text": "THE DATA\nHow can we evaluate whether trading a first round pick for two second round picks and a third round pick is a good idea? One approach is to look at the historical performance of players from these draft rounds.\nI’ve created a data set that will allow us to explore player performance as a function of draft position. If you are curious as to how I obtained and re-arranged these data, you can check out that tutorial here. For this assignment, though, I want to focus on the visualizations.\n\n\nCode\nlibrary(tidyverse)\n\n\nWarning: package 'tidyverse' was built under R version 4.1.3\n\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.3.5     v purrr   0.3.4\nv tibble  3.1.6     v dplyr   1.0.7\nv tidyr   1.2.0     v stringr 1.4.0\nv readr   2.1.2     v forcats 0.5.1\n\n\nWarning: package 'readr' was built under R version 4.1.3\n\n\nWarning: package 'forcats' was built under R version 4.1.3\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\n\nCode\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(readxl)\n\n\nWarning: package 'readxl' was built under R version 4.1.3\n\n\nCode\nNHLDraft<-read.csv(\"NHLDraft.csv\")\nNHLDictionary<-read_excel(\"NHLDictionary.xlsx\")\nglimpse(NHLDraft)\n\n\nRows: 105,936\nColumns: 12\n$ X           <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,~\n$ draftyear   <int> 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001~\n$ name        <chr> \"Drew Fata\", \"Drew Fata\", \"Drew Fata\", \"Drew Fata\", \"Drew ~\n$ round       <int> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3~\n$ overall     <int> 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86~\n$ pickinRound <int> 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23~\n$ height      <int> 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73~\n$ weight      <int> 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209, 209~\n$ position    <chr> \"Defense\", \"Defense\", \"Defense\", \"Defense\", \"Defense\", \"De~\n$ playerId    <int> 8469535, 8469535, 8469535, 8469535, 8469535, 8469535, 8469~\n$ postdraft   <int> 0, 1, 2, 4, 5, 10, 11, 12, 13, 3, 6, 7, 8, 9, 14, 15, 16, ~\n$ NHLgames    <int> 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n\n\nCode\nknitr::kable(NHLDictionary)\n\n\n\n\n\n\n\n\n\n\nAttribute\nType\nDescription\n\n\n\n\ndraftyear\nOrdinal\nCalendar year in which the player was drafted into the NHL.\n\n\nname\nItem\nFull name of the player.\n\n\nround\nOrdinal\nRound in which the player was drafted (1 to 7).\n\n\noverall\nOrdinal\nOverall draft position of the player (1 to 224)\n\n\npickinRound\nOrdinal\nPosition in which the player was drafted in their round (1 to 32).\n\n\nheight\nQuantitative\nPlayer height in inches.\n\n\nweight\nQuantitative\nPlayer weight in pounds.\n\n\nposition\nCategorical\nPlayer position (Forward, Defense, Goaltender)\n\n\nplayerId\nItem\nUnique ID (key) assigned to each player.\n\n\npostdraft\nOrdinal\nNumber of seasons since being drafted (0 to 20).\n\n\nNHLgames\nQuantitative\nNumber of games played in the NHL in that particular season (regular season is 82 games, playoffs are up to 28 more).\n\n\n\n\n\nIn this case, we have a dataframe with all the drafted players since 2000, their position, their draft year and position, and then rows for each season since being drafted (postdraft). The key variable here is NHLgames, which tells us how many games they played in the NHL each season since being drafted."
  },
  {
    "objectID": "posts/Assignment 5/index.html#simple-scatterplot",
    "href": "posts/Assignment 5/index.html#simple-scatterplot",
    "title": "ASSIGNMENT 5",
    "section": "SIMPLE SCATTERPLOT",
    "text": "SIMPLE SCATTERPLOT\nOne thing to realize about professional hockey is that it is pretty rare for a player to play in the NHL right after being drafted. Players get drafted when they are 18 years old, and they usually play in the juniors, minor leagues, or the NCAA for a bit to further develop. Let’s use a scatterplot to visualize this phenomenon with the most recent draft classes.\n\n\nCode\ndraft2022<-NHLDraft%>%\n  filter(draftyear==2022 & postdraft==0)\n\nggplot(draft2022, aes(x=round, y=NHLgames))+\n  geom_point()\n\n\n\n\n\nAs you can see, the players drafted in June of 2022 haven’t played much this season. There are few things wrong with this visualization, however:\n\nOverplotting. All those points on the y=0 line represent about 32 players each. Can you think of a way that adding extra channels might help?\nLabelling. Can we create a solid figure caption and better axis labels for this figure? In your caption, please specify the task(s) the visualizaiton is intended to facilitate, as well as the marks, channels, and key-value pairs used.\nKey-Value pairs: Looks like we are using “round” as a continuous variable. Can we change this to an ordered factor?\n\nIf one of the issues is the ability to distinguish between players (stacked data points), then why not separate by players? Also turn ‘round’ into a channel: shade/saturation.\n\n\nCode\nggplot(draft2022, aes(x= reorder(name, overall), y=NHLgames)) +\n  geom_point(aes(colour = as.factor(round)))+\n  xlab(\"Eager players\") + ylab(\"# games played in first year\")\n\n\n\n\n\nUnfortunately, there are too many names on the X-axis and this is due to 225 unique player’s name showing up. Maybe we should go back to focusing on the round they were picked, since our ultimate goal to visualize if round picks are a predictor of good performance or not. However, to resolve the issue of over plotting, we can try reduction (or derive?) of data. To keep things simple lets take the average games played by players in each round. That should ensure 1 data point for each round. You can’t have over plotting with only 1 data point per category!\n\n\nCode\nAve.column <- NULL\n\nfor(r in 1:7){\n  Average <- ave(draft2022$NHLgames[draft2022$round == r])[1]\n  Ave.column <- rbind(Ave.column, Average)\n}\n\nDF <- data.frame(Round = c(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"),\n                 Average = Ave.column\n                 )\n\nggplot(DF, aes(x=Round, y=Average))+\n  geom_col()+\n  xlab(\"Rounds\") + ylab(\"Average # of first year games\")\n\n\n\n\n\nCaption: Interesting based on this plot/data, it appears that 1st round picks, on average, are more likely to play games in there first year. Marks: points Channels: Length Key-value pairs: In this case Round # is a key? and average # games played by players in that round is the value?"
  },
  {
    "objectID": "posts/Assignment 5/index.html#expanded-scatterplot",
    "href": "posts/Assignment 5/index.html#expanded-scatterplot",
    "title": "ASSIGNMENT 5",
    "section": "EXPANDED SCATTERPLOT",
    "text": "EXPANDED SCATTERPLOT\nThe data from the most recent draft isn’t really helpful for our question. Let’s go back in time and use a draft year that has had some time to develop and reach their potential. How about 2018?\n\n\nCode\ndraft2018<-NHLDraft%>%\n  filter(draftyear==2018 & postdraft<6)\n\nggplot(draft2018, aes(x=round, y=NHLgames))+\n  geom_point()\n\n\n\n\n\nHmmm… in addition to the problem of overplotting, we’ve got an additional issue here. We actually have two keys and one attribute. The attribute is NHLgames, and the keys are round and postdraft, but we are only using round.\nPostdraft indicates the number of seasons after being drafted. We have several choices here. We can make a visualization that uses both keys, or we can somehow summarize the data for one of the keys.\nFor example, let’s say we just wanted to know the TOTAL number of NHL games played since being drafted.\n\n\nCode\ndrafttot2018<- draft2018%>%\n  group_by(playerId, round, overall, position, name)%>%\n  summarise(totgames=sum(NHLgames))\n\n\n`summarise()` has grouped output by 'playerId', 'round', 'overall', 'position'.\nYou can override using the `.groups` argument.\n\n\nCode\nggplot(drafttot2018, aes(x=round, y=totgames))+\n  geom_point()\n\n\n\n\n\nFine, I guess, but we still have to deal with overplotting, and think about whether a scatterplot really helps us accomplish our task. For this figure do the following:\n\nOverplotting. All those points on the y=0 line represent about 32 players each. Can you you think of a way that adding extra channels might help?\nLabelling. Can we create a solid figure caption and better axis labels for this figure? In your caption, please specify the task(s) the visualizaiton is intended to facilitate, as well as the marks, channels, and key-value pairs used.\nKey-Value pairs: Looks like we are using “round” as a continuous variable. Can we change this to an ordered factor?"
  },
  {
    "objectID": "posts/Assignment 5/index.html#scatterplot-with-overall-draft-position",
    "href": "posts/Assignment 5/index.html#scatterplot-with-overall-draft-position",
    "title": "ASSIGNMENT 5",
    "section": "SCATTERPLOT WITH OVERALL DRAFT POSITION",
    "text": "SCATTERPLOT WITH OVERALL DRAFT POSITION\nThis approach might yield a better match with the scatterplot idiom. What if we ignore draft round, and use the player’s overall draft position instead?\n\n\nCode\nggplot(drafttot2018, aes(x=overall, y=totgames))+\n  geom_point()\n\n\n\n\n\nFor this figure, address the following:\n\nWe are trying to address the notion of trading a pick from round 1 for picks from round 2 and 3. Add visual channels to this plot that will help us make that decision.\nCreate a caption and better axis labels for this figure.\nWhat if we wanted to use more than just the 2018 draft class?"
  },
  {
    "objectID": "posts/Assignment 5/index.html#scatterplot-summary",
    "href": "posts/Assignment 5/index.html#scatterplot-summary",
    "title": "ASSIGNMENT 5",
    "section": "SCATTERPLOT SUMMARY",
    "text": "SCATTERPLOT SUMMARY\nWe seem to be running into an issue in terms of overplotting. Scatterplots are great, but they work best for two quantitative attributes, and we have a situation with one or two keys and one quantitative attribute. The thing is, scatterplots can be very useful when part of our workflow involves modeling the data in some way. We’ll cover this kind of thing in future assignments, but just a bit of foreshadowing here:\n\n\nCode\nggplot(drafttot2018, aes(x=round, y=totgames))+\n  geom_point()+\n  geom_smooth()\n\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\nAdding the smoothed line doesn’t eliminate the overplotting problem, but it does indicate that it exists. We’ll cover other potential solutions (including Cody’s violin plots!) to this issue later in the course, when we get to the notions of faceting and data reduction."
  },
  {
    "objectID": "posts/Assignment 5/index.html#simple-bar-chart",
    "href": "posts/Assignment 5/index.html#simple-bar-chart",
    "title": "ASSIGNMENT 5",
    "section": "SIMPLE BAR CHART",
    "text": "SIMPLE BAR CHART\nOne of the best ways to deal with overplotting is to use our keys to SEPARATE and ORDER our data. Let’s do that now. I’ll stick with the summarized data for the 2018 draft year for now.\n\n\nCode\nggplot(drafttot2018, aes(x = name, y=totgames))+\n  geom_col()\n\n\n\n\n\nEpic. We now have a bar (column, really) chart with the key being player name, and the attribute being the total number of games played. We’ve SEPARATED the data using the spatial x-axis position channel, and aligned to that axis as well. But this visualization clearly sucks. You need to make it better by:\n\nAdding a visual channel indicating draft round.\nFixing the order of the x axis.\nMaking a caption and better axis labels.\nFixing the values of the x axis labels so they aren’t such a mess.\n\n\n\nCode\nggplot(drafttot2018, aes(x = reorder(name, overall), y=totgames))+\n  geom_col(aes(colour = round)) +\n  xlab(\"Eager Players\") + ylab(\"Total games played since draft\") +\n  theme(axis.text.x = element_text(angle=90, vjust=.5, hjust=1, size = .5))"
  },
  {
    "objectID": "posts/Assignment 5/index.html#stacked-bar",
    "href": "posts/Assignment 5/index.html#stacked-bar",
    "title": "ASSIGNMENT 5",
    "section": "STACKED BAR?",
    "text": "STACKED BAR?\nStacked bar charts use two keys and one value. Can we leverage this idiom? Perhaps if we used both round and postdraft as our keys and NHLgames as our value…\nThe idea here is that we might be able to get a sense of the temporal pattern of NHL games after a player is drafted. Do first round picks join the NHL earlier? Do they stay in the NHL longer? That kind of thing.\n\n\nCode\nggplot(draft2018, aes(x = postdraft, y=NHLgames, fill=as.factor(round)))+\n  geom_col(position = \"stack\")\n\n\n\n\n\nThis seems like it has some potential, but it definitely needs some work (by you):\n\nYou know the drill by now. Caption! Labels!\nImprove the color palette.\nDo we really only want data from the 2018 draft class?\nConsider the order of rounds within the stack (glyph). Which round is most important? Change the order within the glyphs to reflect this.\n\n\n\nCode\nmycolors <- c(\"#F20295\", \"#F00000\", \"black\", \"#6C007B\", \"#355C7D\", \"cyan\", \"green\")\n\nggplot(draft2018, aes(x = postdraft, y=NHLgames, fill=as.factor(round)))+\n  geom_col(position = \"stack\") +\n  scale_fill_manual(values = mycolors)"
  },
  {
    "objectID": "posts/Assignment 5/index.html#pie-charts-normalized-bar-charts",
    "href": "posts/Assignment 5/index.html#pie-charts-normalized-bar-charts",
    "title": "ASSIGNMENT 5",
    "section": "PIE CHARTS / NORMALIZED BAR CHARTS",
    "text": "PIE CHARTS / NORMALIZED BAR CHARTS\nWe all know that Pie Charts are rarely a good choice, but let’s look at how to make one here. I’ll eliminate all the players drafted in 2018 who never played an NHL game, leaving us 80 players drafted in that year who made “THE SHOW”. Let’s look at how those 80 players were drafted:\n\n\nCode\nplayedNHL2018 <- drafttot2018%>%\n  filter(totgames>0)\n\nggplot(playedNHL2018, aes(x = \"\", fill = factor(round))) +\n  geom_bar(width = 1) +\n  coord_polar(theta = \"y\")\n\n\n\n\n\nObviously this isn’t great, but can you state why? Write a little critique of this visualizaiton that:\n\nConsiders a player who played hundreds of games over their first five years vs a player who played one game in five years.\nEvaluates the relative value of a second round pick and a third round pick.\n\nNow let’s change this to account for the various years post draft:\n\n\nCode\nseasonplayedNHL2018 <- draft2018%>%\n  filter(NHLgames>0)\n\n\nggplot(seasonplayedNHL2018, aes(x = \"\", fill = factor(round))) +\n  geom_bar(width = 1) +\n  coord_polar(theta = \"y\")+\n  facet_wrap(~postdraft)\n\n\n\n\n\nSeems like there is something to work with here, but let’s compare this to a normalized bar chart:\n\n\nCode\nggplot(draft2018, aes(x = postdraft, y=NHLgames, fill=as.factor(round)))+\n  geom_col(position = \"fill\")\n\n\nWarning: Removed 218 rows containing missing values (geom_col).\n\n\n\n\n\nCan you work with this to make it a useful visualization for your friend, Cassandra Canuck?"
  },
  {
    "objectID": "posts/Assignment 5/index.html#heatmap",
    "href": "posts/Assignment 5/index.html#heatmap",
    "title": "ASSIGNMENT 5",
    "section": "HEATMAP?",
    "text": "HEATMAP?\nCould this be useful?\n\n\nCode\nround1<-NHLDraft%>%\n  filter(round==1)\n\nggplot(round1, aes(y = reorder(name, overall), x = postdraft, fill = NHLgames)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"blue\", high = \"red\")"
  },
  {
    "objectID": "posts/Assignment 5/index.html#other-stuff-to-consider",
    "href": "posts/Assignment 5/index.html#other-stuff-to-consider",
    "title": "ASSIGNMENT 5",
    "section": "OTHER STUFF TO CONSIDER",
    "text": "OTHER STUFF TO CONSIDER\n\nDo these visualizations change as a function of player position?\nIs the number of NHL games played really the best metric to use?"
  },
  {
    "objectID": "posts/Assignment 5/index.html#conclusion",
    "href": "posts/Assignment 5/index.html#conclusion",
    "title": "ASSIGNMENT 5",
    "section": "CONCLUSION",
    "text": "CONCLUSION\nBased on your visualizations, what would you advise regarding this trade proposal? Why?"
  },
  {
    "objectID": "posts/BCB 520 - Midterm Portfolio Post/index.html",
    "href": "posts/BCB 520 - Midterm Portfolio Post/index.html",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "",
    "text": "This midterm assignment I will be doing an exploratory analysis on gun violence in the US."
  },
  {
    "objectID": "posts/BCB 520 - Midterm Portfolio Post/index.html#preamble",
    "href": "posts/BCB 520 - Midterm Portfolio Post/index.html#preamble",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "Preamble",
    "text": "Preamble\nPundits are tasked with providing unbiased reporting on new information, as it develops to inform their audiences, in order for society to adapt or adjust to the developing situation. To aid in this effort, many institutions or groups exist to aggregate data on various topics of interest such as gun violence and is often widely available for academics or internet sleuths to analyze, visualize, and interpret. The culmination of these efforts is often a report to answer pertinent questions to topics societies are concerned with.\nHere in the U.S. any citizen has the right to own firearms. However, the proliferation of firearms has many concerned on public safety and crimes committed with firearms. From your average Joe to politicians at the federal level, opinions differ on the threats posed and consequences of wide-spread availability of firearms, ability to conceal or openly carry a firearm. The the advent of social media has increased the flow of information and based on increased reporting of gun related crimes, the topic of firearms back into the forefront of average citizens and policy-makers. However, some people consider the increased reporting on crimes a product of increased flow of information and could mislead society and policy makers into believing crime, in particular gun crime is out of control.\nTherefore in an effort to inform those concerned on the topic of firearms, I will present and interpret the data set described below in an intuitive and discernible manner. One of the main overarching question(s) that will be addressed is:\n\nHas there been a significant increase gun violence?"
  },
  {
    "objectID": "posts/BCB 520 - Midterm Portfolio Post/index.html#data",
    "href": "posts/BCB 520 - Midterm Portfolio Post/index.html#data",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "Data",
    "text": "Data\nFigures made and presented in this post will be based mainly on a U.S. Gun Violence Data set containing gun violence incidents, retrieved from Kaggle.com on 3/21/2023. However, the data set was originally collected from gunviolencearchive.org.\nTo help the reader understand the keys and attributes available in the data set, an example of the data is displayed and each column header is defined to ensure understanding what values and observations mean.\nIf any additional or supplemental data used in any visualizations will be mentioned in figure description.\n\n\nCode\nlibrary(tidyverse)\n\n\n\n\nCode\ngundata <- read.csv(\"Gun violence data 1.csv\")\nglimpse(gundata)\n\n\nRows: 452,787\nColumns: 7\n$ Incident_ID    <int> 92114, 92117, 92119, 92125, 92129, 92133, 92135, 92137,~\n$ Incident_Date  <chr> \"1/1/2014\", \"1/1/2014\", \"1/1/2014\", \"1/1/2014\", \"1/1/20~\n$ State_Code     <chr> \"KY\", \"KY\", \"KY\", \"OK\", \"OK\", \"NY\", \"NY\", \"NY\", \"NY\", \"~\n$ City_Or_County <chr> \"Lexington\", \"Cynthiana\", \"Louisville\", \"Lawton\", \"Okmu~\n$ Address        <chr> \"Sixth St and Elm Tree Ln\", \"US 62\", \"S 38th St and W B~\n$ Killed         <int> 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0~\n$ Injured        <int> 1, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 3, 1, 0, 1, 0, 0, 1, 1~\n\n\nCode\ngundata_attributes <- read.csv(\"Gun_violence_data_descriptions.csv\")\nknitr::kable(gundata_attributes)\n\n\n\n\n\n\n\n\n\n\nColumn.names\nData.Type\nDescription\n\n\n\n\nIncident ID\nItem\nUnique identifier for each incident\n\n\nIncident Date\nAttribute\nThe month, day, and year the incident occurred\n\n\nState_Code\nPosition\n2 letter code representing states where incident occurred\n\n\nCity_or_County\nPosition\nThe city or county where an incident occurred\n\n\nAddress\nPosition\nPhysical location within a city or county where an incident occurred\n\n\nKilled\nAttribute\nNumber of people killed in the incident\n\n\nInjured\nAttribute\nNumber of people injured in the incident"
  },
  {
    "objectID": "posts/BCB 520 - Midterm Portfolio Post/index.html#visualizations",
    "href": "posts/BCB 520 - Midterm Portfolio Post/index.html#visualizations",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "Visualizations",
    "text": "Visualizations\nWe are working with 1 key that identifies each separate gun incident, the dates when incidents occurred, and several position-type data where the incident takes place.\nGiven we are interested in whether there has been an increase in gun violence/crimes within the recent years, it seems only natural to derive total the number of incidents for each year, across the US.\n\n\nCode\ngundata <- gundata %>%\n  separate(Incident_Date, sep=\"/\", into = c(\"month\", \"day\", \"year\"))\n\ntotal_by_year <- summarise(group_by(gundata, Year = year), Incidents = n())\n\nggplot(total_by_year, aes(x= Year, y= Incidents, group = 1)) +\n  geom_line() + geom_point()\n\n\n\n\n\nInterestingly, from the year 2014 there was an increase of gun incidents up until 2020, then there was a sharp decline in gun violence to levels less than 2014. Although all violence is tragic, fortunately not every incident results in casualties, but injuries or sometimes neither! Compared to 2014 the amount of gun violence appears to be dropping, but for the incidents that do occur: are more people dying, or getting injured? Lets have a look at whether there was an increase in either deaths, injuries or neither.\n\n\nCode\nTotals <- total_by_year\n\nBoth_by_year <- summarise(group_by(gundata[gundata$Killed >= 1 & gundata$Injured >= 1,], Year = year), Incidents = n())\n\nCasualties_by_year <- summarise(group_by(gundata[gundata$Killed >= 1 & gundata$Injured == 0,], Year = year), Incidents = n())\n\nInjuries_by_year <- summarise(group_by(gundata[gundata$Killed == 0 & gundata$Injured >= 1,], Year = year), Incidents = n())\n\nneither_by_year <- summarise(group_by(gundata[gundata$Killed == 0 & gundata$Injured == 0,], Year = year), Incidents = n())\n\n\nTotals <- bind_rows(Totals, Casualties_by_year, Injuries_by_year, neither_by_year, Both_by_year)\nTotals$Type <- c(rep_len(\"Total Incidents\", 9), rep(\"Death\", 9), rep(\"Injured\", 9), rep(\"Neither\", 9), rep(\"Death and Injuries\", 9))\n\n\nggplot(Totals, aes(x= Year, y= Incidents, group = Type, color = Type)) +\n  geom_line() + geom_point()\n\n\n\n\n\nThis is interesting, but perhaps worrying as the data first suggested the U.S. was experiencing less gun violence nationwide. Despite, the total number of violent gun incidents drastically decreased between the years 2020 and 2022, to underneath 2014 levels. However, the amount of deaths and/or injuries per year increased, or at the very least stayed constant! The apparent decrease in gun incidents is a result of non-casualty incidents decreasing.\nEven though there is an apparent decrease in gun violence incidents, it appears the likelihood of a death and/or injury occurring per incident is increasing each year. Could we possibly reflect that by introducing a new channel like size of each point based on the average number of deaths and/or injuries per incident for each year?\n\n\nCode\nM_KIT_per_year <- gundata %>% \n  group_by(year) %>%\n  summarise(mean = mean(c(Killed, Injured)))\n\nM_K_per_year <- gundata %>% \n  group_by(year) %>%\n  summarise(mean = mean(Killed))\n\nM_I_per_year <- gundata %>%\n  group_by(year) %>%\n  summarise(mean = mean(Injured))\n\nNeither <- rep(0, 9)\n\nM_KI_per_year <- gundata %>% \n  group_by(year) %>%\n  summarise(mean = mean(c(Killed, Injured)))\n\nMean <- c(M_KIT_per_year$mean, M_K_per_year$mean, M_I_per_year$mean, Neither, M_KI_per_year$mean)\n\nTotals$Mean <- Mean\n\nggplot(Totals, aes(x= Year, y= Incidents, group = Type, color = Type)) +\n  geom_line() + geom_point(aes(size = Mean)) +\n  scale_size(range = c(1, 10), breaks = c(0, .50, .75, .9))\n\n\n\n\n\nAlthough we were able to visually observe some interesting details about the data using line scatter plot idiom, I believe we have reached a limit. We could continue to add additional channels to convey more information, but the last addition of point size to convey the average number of deaths/injuries per incident does not work very well. This due to the average number of deaths or injuries per year being fairly constant and outliers have negligible impact on the point size when there are 40000+ incidents with only death or injury each year.\nLet us try to stacked bar plot idiom, I think it will be an improvement over the scatterplot, mostly because we can normalize the data to utilizes percentages and describe each category as parts of a whole. When dealing with large numbers, they tend to lose meaning when comparing, thus viewing things as percentage increases or decreases is more important than the raw numbers.\n\n\nCode\nggplot(Totals, aes(x= Year, y= Incidents, group = Type, color = Type)) +\n  geom_line() + geom_point()\n\n\n\n\n\nCode\nggplot(Totals[10:45,], aes(x = Year, y= Incidents, fill=as.factor(Type)))+\n  geom_col(position = \"stack\")+\n  labs(fill = \"Casualty Type\") +\n  geom_text(aes(label = Incidents), position = position_stack(vjust = .5))\n\n\n\n\n\nCode\nggplot(Totals[10:45,], aes(x = Year, y= Incidents, fill=as.factor(Type)))+\n  geom_col(position = \"fill\") +\n  labs(fill = \"Casualty Type\")\n\n\n\n\n\nBetween the years 2014 and 2022, we can more clearly observe a decrease in total incidents, however the amount of incidents resulting in death, injury, or both increased when comparing 2014 and 2022 specifically. Despite the apparent down trend in total incidents, it appears the each incident that does occur is more likely to result in at least one casualty.\nAlthough no new information was added based on the scatter plot, the stacked bar plot idiom seems to be better, even if only slightly. Using length on the Y axis to represent the total incidents per year is better than having it be its own category on the scatter plot, in theory this should reduce the cognitive demands on the reader. Also, the connecting lines are not necessary to expressing the order of time.\nIf you recall, we have position data in the form of States, down to the county level. The U.S. is a very large and diverse country, are the trends observed so far applicable to the entire country? or does each state have its own pattern of gun violence?\n\n\nCode\nlibrary(maps)\n\n\n\n\nCode\n# Load the map data\ncounties <- map_data(\"county\")\n\n# Create the plot\nggplot() +\n  # Add the map data for the lower 48 states\n  geom_polygon(data = counties, aes(x = long, y = lat, group = group, fill = region), color = \"black\") +\n  # Add the map data for Alaska\n  geom_polygon(data = subset(counties, region == \"alaska\"), aes(x = long, y = lat, group = group), color = \"red\", fill = \"black\") +\n  coord_map(\"albers\", lat0 = 39, lat1 = 45) +  # Center and zoom the map\n  # Add the map data for Hawaii\n  geom_polygon(data = subset(counties, region == \"hawaii\"), aes(x = long, y = lat, group = group), color = \"red\", fill = \"black\") +\n  # Customize the plot\n  theme_void() +\n  ggtitle(\"United States Map by County\") +\n  labs(caption = \"Source: U.S. Census Bureau\") +\n  theme(plot.title = element_text(size = 16, hjust = 0.5),\n        plot.caption = element_text(size = 8, hjust = 0),\n        legend.position = \"none\")"
  },
  {
    "objectID": "posts/BCB 520 - Midterm Portfolio Post/index.html#summary",
    "href": "posts/BCB 520 - Midterm Portfolio Post/index.html#summary",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "Summary",
    "text": "Summary\nWhen only taking into account the number of isolated incidents, there has been a sharp decrease in gun violence across the entire U.S.\nHowever, when incidents are separated by whether death, injury, both, or neither occurred, revealed the decrease in total incidents is mostly due to non-casualty incidents plummeting, while death, injury, or both increased (or at least stayed constant)."
  },
  {
    "objectID": "posts/BCB 520 - Midterm Portfolio Post/index.html#conclusions",
    "href": "posts/BCB 520 - Midterm Portfolio Post/index.html#conclusions",
    "title": "BCB 520 - Midterm Portfolio Post",
    "section": "Conclusions",
    "text": "Conclusions\nGun violence is getting rarer, but deadlier"
  },
  {
    "objectID": "posts/MarksChannels/index.html",
    "href": "posts/MarksChannels/index.html",
    "title": "ASSIGNMENT 4",
    "section": "",
    "text": "Every time you create a figure, it needs a caption. The text in that section of your assignment should also briefly describe the data set you are using, especially the attributes used for the visualization.\nIn addition, make sure the visualization task actually requires the particular concept.\nFor example, don’t just make a scatterplot with one red dot for the Popout exercise.\nYou need to describe a task that requires we IDENTIFY that point.\n\n\nCode\nstack <- read.csv(\"2022-03-21_trim-stacked.csv\")\n\nhist(stack$logFC)\n\n\n\n\n\nCode\nhist(stack$logFC, breaks = 1000)\n\n\n\n\n\nThe goal of figure 1 is to summarize the distribution of log fold changes observed across all mutant samples. A description of the results would be the majority of proteins detected and quantified did not have its steady-state levels impacted by at least one mutant condition. Using only this figure, it appears that only a small percentile of proteins detected had there steady-state levels impacted in at least one mutant condition.\nA limitation of histograms is it does not show the precise number of proteins with log fold changes between 1.5 and 1.7 for example. In an attempt to answer this pressing question, the second figure has an increased number of bins to narrow in the 1.5-1.7 log fold change region, but I still do not know the exact answer.\n\n\nCode\np350 <- read.csv(\"350_matrix_LogFC.csv\")\n\nplot(p350$R46G, p350$A583T)\n\n\n\n\n\nCode\ncolors <- colorRampPalette(c(\"red\", \"blue\"))\n\np350$color.order <- findInterval(p350$A583T, sort(p350$A583T))\n\nplot(x = p350$R46G[order(p350$R46G)],\n     col = colors(nrow(p350))[p350$color.order])\n\n\n\n\n\nThe goal of these figures is to display if these two mutants (R46G vs A583T) affect the same proteins/genes similarly, correlation suggests these mutants are doing similar things in vivo.\nInstead of position,I used hue for A583T mutant logFC numbers. Solid red is lowest LogFC in the A583T mutation, with purple representing Log FC numbers near zero (Wild-type levels) and Blue is the highest log FC values.\n\n\nCode\nplot(stack$logFC[stack$P.Value <= .055 & stack$contrast == \"WTHsc82_vs_R46G\"], \n     log(stack$Half.life[stack$P.Value <= .055 & stack$contrast == \"WTHsc82_vs_R46G\"]))"
  },
  {
    "objectID": "posts/Spatial Practice/index.html",
    "href": "posts/Spatial Practice/index.html",
    "title": "Practice with Spatial Data",
    "section": "",
    "text": "In this assignment, we’ll consider some of the tools and techniques for visualizing spatial data. Spatial data comes in two broad categories, geographic and spatial fields. Let’s practice a few visualizations to get a feel for how these things work!"
  },
  {
    "objectID": "posts/Spatial Practice/index.html#geographic-maps",
    "href": "posts/Spatial Practice/index.html#geographic-maps",
    "title": "Practice with Spatial Data",
    "section": "GEOGRAPHIC MAPS!",
    "text": "GEOGRAPHIC MAPS!\nIn class I bet Ronald that he would end up creating some kind of map based visualization before he graduated with his PHD. This is because he works on Malaria - a terrible disease with a strong spatial component to its risk levels. Let’s get some Malaria data and map it!\nThe data I obtained were from the Malaria Atlas. I downloaded a csv for 10 years of data for all the countries the had on file.\n\n\nCode\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(dplyr)\n\nMalaria <- read.csv(\"National_Unit_data.csv\")\n\nIncidence<- Malaria%>%\n  filter(Metric == \"Infection Prevalence\" & Year == \"2019\")%>%\n  mutate(Prevalence = Value)%>%\n  select(c(ISO3, Prevalence))\n\n\nNow I’m going to use the rnaturalearth package to create contry polygons. Then I’ll add the Malaria data to that data frame.\n\n\nCode\nworld_map <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nmap_data <- world_map %>%\n  left_join(Incidence, by = c(\"iso_a3\" = \"ISO3\"))\n\n\nNow I will make a plot!\n\n\nCode\nggplot() +\n  geom_sf(data = map_data, aes(fill = Prevalence)) +\n  scale_fill_gradient(low = \"white\", high = \"red\", na.value = \"gray\", name = \"Malaria Prevalence\") +\n  theme_minimal() +\n  theme(axis.text = element_blank(), axis.ticks = element_blank(), axis.title = element_blank()) +\n  labs(title = \"Malaria Prevalence by Country\")\n\n\n\n\n\nOh SNAP! We made a MAP!\nHey! That rhymes!\nWhat is missing? Units? Is that actually prevalence? We sure left a lot of data on the table? Can we add some kind of time thing? Change the variable?"
  },
  {
    "objectID": "posts/Spatial Practice/index.html#spatial-fields",
    "href": "posts/Spatial Practice/index.html#spatial-fields",
    "title": "Practice with Spatial Data",
    "section": "SPATIAL FIELDS",
    "text": "SPATIAL FIELDS\nSpatial field data refers to data that has a continuous spatial distribution and can be measured at any location within the defined area. Here are some interesting examples of spatial field data:\n\nAir temperature: Air temperature data collected from weather stations or remote sensing technologies can be used to create temperature maps or to study climate change, urban heat islands, and other environmental phenomena. TROPICAL CYCLONE!\nPrecipitation: Rainfall, snowfall, or other forms of precipitation data collected from weather stations or satellites can be used to study the hydrological cycle, flood risk, droughts, or water resource management.\nSoil moisture: Soil moisture data collected from in situ sensors or remote sensing technologies can be used to study agricultural productivity, irrigation management, droughts, and land degradation. Elevation data (Digital Elevation Models, DEMs):\nElevation data collected from satellite-based radar, LiDAR, or photogrammetry can be used to study topography, watershed delineation, flood risk, landslides, or geomorphology.\nVegetation indices: Indices like the Normalized Difference Vegetation Index (NDVI) or Enhanced Vegetation Index (EVI) derived from satellite imagery can be used to study vegetation health, land cover change, deforestation, agricultural productivity, and carbon sequestration.\nAir quality: Data on air pollutants like PM2.5, PM10, NO2, SO2, O3, and CO collected from ground-based monitors or satellites can be used to study the impact of pollution on human health, urban planning, or environmental policy.\nOceanographic data: Sea surface temperature, salinity, and chlorophyll-a concentration data collected from buoys, ships, or satellites can be used to study ocean currents, climate change, or marine ecosystems. OCEAN CURRENTS!\nPopulation density: Spatially explicit population density data can be used to study urbanization, migration patterns, infrastructure planning, or public health.\nLand use and land cover: Land use and land cover data collected from satellite imagery can be used to study urban growth, deforestation, habitat fragmentation, or landscape ecology.\nSeismic activity: Spatial distribution of earthquakes and their magnitudes can be used to study tectonics, fault zones, seismic hazards, or infrastructure resilience. DARK NIGHTS IN ANTAKYA\nSPORTS! Let’s check out a baseball example!\n\n\n\nCode\n# install.packages(\"baseballr\")\nlibrary(remotes)\n\n\nWarning: package 'remotes' was built under R version 4.1.3\n\n\nCode\n# install_github(\"bayesball/CalledStrike\")\n\n\n\n\nCode\nlibrary(CalledStrike)\n\n\nLoading required package: shiny\n\n\nWarning: package 'shiny' was built under R version 4.1.3\n\n\nLoading required package: baseballr\n\n\nWarning: package 'baseballr' was built under R version 4.1.3\n\n\nLoading required package: mgcv\n\n\nLoading required package: nlme\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nThis is mgcv 1.8-38. For overview type 'help(\"mgcv-package\")'.\n\n\nLoading required package: metR\n\n\nWarning: package 'metR' was built under R version 4.1.3\n\n\n\nAttaching package: 'metR'\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nCode\n#ShinyDemo()\n\n\nThis example is the Pitch_Locations example from byaesball’s CalledStrike Github Repository\n\nIntroduction\nThere are three functions for visualizing pitch locations.\n\nThe function location_compare() will graph the pitch location for a data frame or list of data frames.\nThe function location_count() will show the locations of pitches for a specific pitcher on a particular count.\nThe function location_count_compare() will graph the pitch locations for a specific pitcher for several values of the count.\n\n\n\nData\nThe package includes the dataset sc_pitchers_2019 that contains Statcast data for 20 pitchers for the 2019 season.\n\n\nPitch Locations for a List\nSuppose we want to compare the locations of the fastballs thrown by Aaron Nola and Trevor Bauer.\nI find the subset of data I need and then create a list dividing the data by pitcher.\n\n\nCode\nd <- filter(sc_pitchers_2019, \n            pitcher %in% c(605400, 545333),\n            pitch_type == \"FF\")\nds <- split(d, d$pitcher)\nnames(ds) <- c(\"Bauer\", \"Nola\")\n\n\nNow we can construct the graph.\n\n\nCode\nlocation_compare(ds)\n\n\nWarning: Removed 22 rows containing non-finite values\n(`stat_density2d_filled()`).\n\n\n\n\n\n\n\nPitch Locations for a Specific Count\nSuppose we want to look at the locations of Aaron Nola’s pitches on a 0-0 count. I can find Nola’s MLBAM id number by use of the chadwick dataset (also included in the package) that contains the id numbers for all players.\n\n\nCode\nchadwick %>% \n  filter(name_last == \"Nola\", name_first == \"Aaron\")\n\n\n  name_first name_last key_mlbam\n1      Aaron      Nola    605400\n\n\nTo produce the graph, type\n\n\nCode\nlocation_count(sc_pitchers_2019, \n               605400, \"Aaron Nola\", \"0-0\")\n\n\nWarning: Removed 4 rows containing non-finite values\n(`stat_density2d_filled()`).\n\n\n\n\n\n\n\nPitch Locations Across a Group of Counts\nSuppose we want to compare Nola’s pitch locations across the counts “0-0”, “1-0”, “0-1”, “0-2”\n\n\nCode\nlocation_count_compare(sc_pitchers_2019, \n               605400, \"Aaron Nola\", \n               \"R\", \"Offspeed\", \n               c(\"0-0\", \"1-0\", \"0-1\", \"0-2\"))\n\n\nWarning: Removed 4 rows containing non-finite values\n(`stat_density2d_filled()`).\n\n\n\n\n\nEND"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\nIn this blog I hope to enlighten the world about the Hsp90 protein and how it impacts your cells!"
  }
]